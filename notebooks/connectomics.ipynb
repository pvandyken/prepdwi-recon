{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import subprocess as sp\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import more_itertools as itx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    4,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    3,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    3,\n",
    "    3,\n",
    "    3,\n",
    "    3,\n",
    "    4,\n",
    "    1,\n",
    "    3,\n",
    "    4,\n",
    "    2,\n",
    "    0,\n",
    "    4,\n",
    "    1,\n",
    "    1,\n",
    "    3,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = {\n",
    "    1: \"HC\",\n",
    "    2: \"FEP\",\n",
    "    3: \"Treatment 3+ yr\",\n",
    "    4: \"High risk\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids import BIDSLayout\n",
    "\n",
    "# layout = BIDSLayout(\"results/prepdwi_recon\", validate=False)\n",
    "layout = BIDSLayout(\"../..\", validate=False, database_path=\"../../.pybids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fury.io as fio\n",
    "import fury.utils as futil\n",
    "import fury.lib as flib\n",
    "import nibabel as nib\n",
    "def node_sizes(path):\n",
    "    pld = fio.load_polydata(path)\n",
    "    cluster_id = flib.numpy_support.vtk_to_numpy(pld.GetCellData().GetArray(\"parcel_idx\"))\n",
    "    counts = defaultdict(lambda: 0)\n",
    "    for i in cluster_id:\n",
    "        counts[i] += 1\n",
    "    return counts\n",
    "\n",
    "def node_sizes_relative(path):\n",
    "    pld = fio.load_polydata(path)\n",
    "    cluster_id = flib.numpy_support.vtk_to_numpy(pld.GetCellData().GetArray(\"parcel_idx\"))\n",
    "    counts = [0] * (max(cluster_id)+1)\n",
    "    for i in cluster_id:\n",
    "        counts[i] += 1\n",
    "    spread = max(counts) - min(counts)\n",
    "    for i in range(len(counts)):\n",
    "        counts[i] = counts[i]/spread\n",
    "    return counts\n",
    "\n",
    "\n",
    "def degree_sizes_relative(degrees):\n",
    "    spread = max(degrees.values()) - min(degrees.values())\n",
    "    for i in range(len(degrees)):\n",
    "        degrees[i] = degrees[i]/spread\n",
    "    return degrees\n",
    "\n",
    "def mesh_size(path):\n",
    "    if Path(path).suffix in [\".vtk\", \".vtp\"]:\n",
    "        pld = fio.load_polydata(path)\n",
    "        return len(futil.get_polydata_triangles(pld))\n",
    "    pld = nib.load(path)\n",
    "    return len(pld.agg_data('triangle'))\n",
    "\n",
    "def node_size_at_points(df: pd.DataFrame, points, column):\n",
    "    df = df.sort_values(column).reset_index(drop=True)\n",
    "    num_rows = len(df[column])\n",
    "    return pd.DataFrame({\n",
    "        column: [df[column][int((num_rows-1) * point)] for point in points],\n",
    "        \"point\": points\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness(b_vals, threshold=.5):\n",
    "    vals = b_vals.values()\n",
    "    b_range = max(vals) - min(vals)\n",
    "    margin = b_range*threshold + min(vals)\n",
    "    above = dict(filter(lambda val: val[1]>=margin, b_vals.items()))\n",
    "    # return above\n",
    "    # b = dict(zip(it.count(), sorted(b_vals)))\n",
    "    df = pd.DataFrame({\"betweenness\": above})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resources/tract-assignments/hemispheric\", 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "all_bundles = [re.search(r\"^cluster_(\\d+)\\.vtp$\", s)[1] for s in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "def filter_logile(matrix, bin: int, num_bins: int = 10):\n",
    "    if bin >= num_bins:\n",
    "        raise ValueError(\"bin must be less then num_bins\")\n",
    "    masked = np.ma.masked_equal(matrix, 0)\n",
    "    log = np.ma.log10(masked)\n",
    "    threshold = ((log.max() - log.min()) * bin / num_bins) + log.min()\n",
    "    cp = copy.deepcopy(matrix)\n",
    "    cp[log <= threshold] = 0\n",
    "    return cp\n",
    "\n",
    "def hex_to_rgb(hex_color: str) -> tuple:\n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    if len(hex_color) == 3:\n",
    "        hex_color = hex_color * 2\n",
    "    return int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)\n",
    "\n",
    "def get_lut(path):\n",
    "    with open(path) as f:\n",
    "        lines = [line.strip().split() for line in f.readlines()]\n",
    "    return {int(key): val for key, val in zip(*list(zip(*lines))[0:2])}\n",
    "\n",
    "def lut_label(data, path):\n",
    "    lut = get_lut(path)\n",
    "    return pd.DataFrame(data).rename(index=lut, columns=lut)\n",
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "def distribution_plot(df, x, y: str):\n",
    "\n",
    "    std_col = y+\"_std\"\n",
    "    grouper = df.groupby([\"category\", x])\n",
    "    ddf = pd.concat([\n",
    "        grouper.mean(),\n",
    "        grouper.std().rename({y: std_col}, axis=\"columns\"),\n",
    "    ], axis=1).reset_index().set_index(\"category\")\n",
    "    fig = px.line(\n",
    "        ddf,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        color=ddf.index,\n",
    "        width=800,\n",
    "        height=600,\n",
    "        labels={\n",
    "            \"x\": \"Nodes sorted by increasing degree\",\n",
    "            \"node_size\": \"Node Size (# triangles)\",\n",
    "            \"betweenness\": \"Betweenness\",\n",
    "            \"degree\": \"Degree\"\n",
    "        },\n",
    "        title=f\"{y.capitalize().replace('_', ' ')} distribution\",\n",
    "    )\n",
    "    buttons = []\n",
    "    num_traces = len(ddf.index.unique())\n",
    "    for i, cat in enumerate(ddf.index.unique()):\n",
    "        fig.add_traces([\n",
    "            go.Scatter(\n",
    "                x=ddf.loc[cat, x],\n",
    "                y=ddf.loc[cat, std_col]+ddf.loc[cat,y],\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=0),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=ddf.loc[cat, x],\n",
    "                y=ddf.loc[cat,y]-ddf.loc[cat, std_col],\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=0),\n",
    "                fill='tonexty',\n",
    "                fillcolor=f'rgba{(*hex_to_rgb(px.colors.qualitative.Plotly[i]), 0.2)}'\n",
    "            )\n",
    "        ])\n",
    "        buttons.append({\n",
    "            \"method\": 'restyle',\n",
    "            \"visible\": True,\n",
    "            \"label\": cat,\n",
    "            \"args\": [{\n",
    "                \"visible\": False\n",
    "            }, [i, num_traces + i*2, num_traces + i*2 + 1]],\n",
    "            \"args2\": [{\n",
    "                \"visible\": True,\n",
    "            }, [i, num_traces + i*2, num_traces + i*2 + 1]]\n",
    "        })\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=50, r=50, t=50, b=50),\n",
    "        showlegend=False,\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"buttons\",\n",
    "                direction=\"right\",\n",
    "                x=1,\n",
    "                y=-0.2,\n",
    "                showactive=True,\n",
    "                buttons=buttons,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def figures_to_html(figs, filename=\"dashboard.html\"):\n",
    "    with open(filename, 'w') as dashboard:\n",
    "        dashboard.write(\"<html><head></head><body>\" + \"\\n\")\n",
    "        for fig in figs:\n",
    "            inner_html = fig.to_html().split('<body>')[1].split('</body>')[0]\n",
    "            dashboard.write(inner_html)\n",
    "        dashboard.write(\"</body></html>\" + \"\\n\")\n",
    "\n",
    "def nb_cache(name, root=\".\", reset_cache=False):\n",
    "    import inspect\n",
    "    cache_file = Path(root, \".ipynb_cache\", name).with_suffix(\".pyc\")\n",
    "    def do_cache(func, *args, **kwargs):\n",
    "        if cache_file.exists() and not reset_cache:\n",
    "            with cache_file.open('rb') as f:\n",
    "                return pickle.load(f)\n",
    "        result = func(*args, **kwargs)\n",
    "        with cache_file.open('wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "        return result\n",
    "    def wrapper(func) -> Any:\n",
    "        def inner(*args, **kwargs):\n",
    "            return do_cache(func, *args, **kwargs)\n",
    "        return inner\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Subject\n",
    "\n",
    "Here, test a single subject and view the connection density as a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.genfromtxt(layout.get(subject=\"034\", datatype=\"dwi\", suffix=\"connectome\")[0].path, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_logile(c, 1)\n",
    "np.fill_diagonal(filtered, 0)\n",
    "G = nx.from_numpy_matrix(filtered)\n",
    "import math\n",
    "for edge in G.edges:\n",
    "    G.edges[edge][\"distance\"] = -math.log10(G.edges[edge][\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = nx.sigma(G)\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = get_lut(\"resources/BN_Atlas_freesurfer/BN_Atlas_210_LUT.txt\")\n",
    "df = pd.DataFrame(c).rename(index=lut, columns=lut)\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df, cmap=\"coolwarm\", square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIGjs2xlpdlg"
   },
   "outputs": [],
   "source": [
    "# Weight distribution plot\n",
    "bins = np.arange(np.sqrt(len(np.concatenate(filtered))))\n",
    "bins = (bins - np.min(bins))/np.ptp(bins)\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "# Distribution of raw weights\n",
    "rawdist = sns.histplot(filtered.flatten(), bins=bins, kde=False, ax=axes[0])\n",
    "rawdist.set(xlabel='Correlation Values', ylabel = 'Density Frequency')\n",
    "\n",
    "# Probability density of log10\n",
    "log10dist = sns.histplot(np.log10(filtered).flatten(), kde=False, ax=axes[1])\n",
    "log10dist.set(xlabel='log(weights)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Subjects\n",
    "\n",
    "Loop through all subjects and gather various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_graphs(filter_level = 1, drop = []):\n",
    "    for bidsfile in layout.get(datatype=\"dwi\", suffix=\"connectome\"):\n",
    "        sub = int(bidsfile.entities['subject'])\n",
    "        if len(categories) <= sub:\n",
    "            print(f\"Dropped {sub} (out of range)\")\n",
    "            continue\n",
    "        cat = categories[sub]\n",
    "        if cat not in cats:\n",
    "            print(f\"Dropped {sub} (no diagnosis assigned)\")\n",
    "            continue\n",
    "        c = np.genfromtxt(bidsfile.path, delimiter=\",\")\n",
    "        np.fill_diagonal(c, 0)\n",
    "        filtered = filter_logile(c, filter_level)\n",
    "        df = lut_label(filtered, \"resources/BN_Atlas_freesurfer/BN_Atlas_210_LUT.txt\")\n",
    "        df.drop(index=\"Unknown\", columns=\"Unknown\", inplace=True)\n",
    "        dropped = drop(sub) if callable(drop) else drop\n",
    "        df.drop(index=dropped, columns=dropped, inplace=True)\n",
    "        G = nx.from_pandas_adjacency(df)\n",
    "        for edge in G.edges:\n",
    "            G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "        yield sub, cat, G, dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_properties(sub, cat, G, drop_regions = []):\n",
    "        try:\n",
    "            return {\n",
    "                \"subject\": sub,\n",
    "                \"category\": cats[cat],\n",
    "                \"degree\":np.mean([*zip(*G.degree)][1]),\n",
    "                \"num_regions\": len(G.nodes),\n",
    "                \"dropped_regions\": list(drop_regions),\n",
    "                \"num_connected_comps\": nx.number_connected_components(G),\n",
    "                \"largest_connected_comp\": len(max(nx.connected_components(G), key=len)),\n",
    "                \"density\": nx.density(G),\n",
    "                \"transitivity\": nx.transitivity(G),\n",
    "                \"efficiency\": nx.global_efficiency(G)\n",
    "            }\n",
    "        except KeyError as err:\n",
    "            print(sub)\n",
    "            raise err\n",
    "\n",
    "@nb_cache(\"subject_properties\")\n",
    "def subject_df(drop_regions = []):\n",
    "    rows = []\n",
    "    for sub, cat, G, dropped in subject_graphs(drop=drop_regions):\n",
    "        try:\n",
    "            rows.append(subject_properties(sub, cat, G, dropped))\n",
    "        except KeyError as err:\n",
    "            print(sub)\n",
    "            raise err\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = subject_df()\n",
    "fig = px.violin(\n",
    "    df,\n",
    "    x=\"category\",\n",
    "    color=\"category\",\n",
    "    y=\"density\",\n",
    "    points=\"outliers\",\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"num_regions\": \"# Regions\",\n",
    "        \"category\": \"Group\"\n",
    "    },\n",
    "    title=\"Number of nodes\",\n",
    "    hover_data=[\"subject\"]\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb_cache(\"nodal_properties\")\n",
    "def nodal_properties():\n",
    "    rows = []\n",
    "    for sub, cat, G in subject_graphs(2):\n",
    "        b = nx.betweenness_centrality(G, weight=\"distance\")\n",
    "        for node in G:\n",
    "            rows.append({\n",
    "                \"node\": node,\n",
    "                \"subject\": sub,\n",
    "                \"category\": cats[cat],\n",
    "                \"degree\": G.degree[node],\n",
    "                \"clust_coeff\": nx.clustering(G, nodes=node),\n",
    "                \"path_length\": np.mean(list(nx.shortest_path_length(G, source=node, weight=\"distance\").values())),\n",
    "                \"betweenness\": b[node],\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "def property_rank(df, columns=[], inverse_columns=[]):\n",
    "    names = df.index.names[:-1]\n",
    "    def rank(df, column, inverse=False):\n",
    "        df.sort_values(by=[*names, column], ascending=not inverse, inplace=True)\n",
    "        for cat in df.reset_index().set_index(names).index.unique():\n",
    "            nodes = df.loc[cat].index\n",
    "            for i, node in enumerate(nodes):\n",
    "                df.loc[\n",
    "                    (*itx.always_iterable(cat), node), f\"{column}_rank\"\n",
    "                ] = i/len(nodes)\n",
    "    for column in columns:\n",
    "        rank(df, column)\n",
    "    for column in inverse_columns:\n",
    "        rank(df, column, inverse=True)\n",
    "    return df\n",
    "\n",
    "def hubness(df, threshold = None, ivars=[\"category\"]):\n",
    "    grouped = df.groupby([*ivars, \"node\"]).mean()\n",
    "    cols = [\"betweenness\", \"degree\"]\n",
    "    inv_cols = [\"path_length\", \"clust_coeff\"]\n",
    "    ranked = property_rank(grouped, columns=cols, inverse_columns=inv_cols)\n",
    "    ranked[\"hubness\"] = 0\n",
    "    for col in it.chain(cols, inv_cols):\n",
    "        if threshold is None:\n",
    "            ranked[\"hubness\"] += ranked[f\"{col}_rank\"]\n",
    "        else:\n",
    "            ranked[\"hubness\"] += (ranked[f\"{col}_rank\"] > threshold).astype(int)\n",
    "    return ranked\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"clust_coe\"\n",
    "indexed = property_rank(nodal_properties().set_index([\"category\", \"subject\", \"node\"]), [col])\n",
    "distribution_plot(indexed, x=col+\"_rank\", y=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb_cache(\"hubness\")\n",
    "def get_hubs():\n",
    "    return hubness(nodal_properties(), ivars=[\"category\", \"subject\"])\n",
    "hubs = get_hubs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [\"degree\", \"clust_coeff\", \"path_length\", \"betweenness\"]\n",
    "\n",
    "plt.figure(figsize=(30, 50))\n",
    "plt.subplot(1, 3, 1)\n",
    "table1 = (\n",
    "    hubs\n",
    "    .loc[\"HC\"]\n",
    "    .reset_index()\n",
    "    .pivot(index=\"node\", columns=\"subject\", values=\"hubness\")\n",
    ")\n",
    "sns.heatmap(table1, cmap=\"viridis\", square=True, cbar=False)\n",
    "plt.subplot(1, 3, (2,3))\n",
    "table2 = (\n",
    "    hubs\n",
    "    .loc[\"FEP\"]\n",
    "    .reset_index()\n",
    "    .pivot(index=\"node\", columns=\"subject\", values=\"hubness\")\n",
    ")\n",
    "sns.heatmap(table2, cmap=\"viridis\", square=True, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drop_func(i, hub_df):\n",
    "    indexed = (\n",
    "        hub_df\n",
    "        .reset_index()\n",
    "        .set_index([\"subject\", \"node\"])\n",
    "        .sort_values([\"subject\", \"hubness\"], ascending=False)\n",
    "    )\n",
    "    def drop_func(sub):\n",
    "        return indexed.loc[sub].index[:i]\n",
    "    return drop_func\n",
    "    \n",
    "\n",
    "def _get_subject_df(x):\n",
    "    return subject_df(drop_regions=get_drop_func(x, hubs))\n",
    "import multiprocessing as mp\n",
    "@nb_cache(\"attack_analysis\")\n",
    "def attack_analysis():\n",
    "    with mp.Pool(processes=32) as pool:\n",
    "        dfs = pool.map(\n",
    "            _get_subject_df,\n",
    "            range(hubs.reset_index().groupby(\"subject\").count().max()[0])\n",
    "        )\n",
    "    # for i in range(hubs.reset_index().groupby(\"subject\").count().max()[0]):\n",
    "    #     dfs.append(subject_df(drop_regions = get_drop_func(i, hubs)))\n",
    "    return pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = attack_analysis()\n",
    "df[\"num_dropped\"] = df[\"num_regions\"].max() - df[\"num_regions\"]\n",
    "figures_to_html([\n",
    "    distribution_plot(df, x=\"num_dropped\", y=col) \n",
    "    for col in [\n",
    "        \"transitivity\",\n",
    "        \"efficiency\",\n",
    "        \"density\",\n",
    "        \"num_connected_comps\",\n",
    "        \"largest_connected_comp\",\n",
    "        \"degree\",\n",
    "    ]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [\"degree\", \"clust_coeff\", \"path_length\", \"betweenness\"]\n",
    "df = nodal_properties()\n",
    "\n",
    "table = (\n",
    "    hubness(df)\n",
    "    .reset_index()\n",
    "    .pivot(index=\"node\", columns=\"category\", values=\"hubness\")\n",
    "    .reindex(columns=[\"HC\", \"FEP\", \"Treatment 3+ yr\", \"High risk\"])\n",
    ")\n",
    "plt.figure(figsize=(20,40))\n",
    "sns.heatmap(table, cmap=\"viridis\", square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_counts = [dict(zip(all_bundles, it.repeat(0))) for _ in range(4)]\n",
    "major_edges = {}\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    connectome = d[\"connectome\"]\n",
    "    data = copy.deepcopy(connectome.matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "    edges = betweenness(nx.edge_betweenness_centrality(G, weight=\"distance\"), threshold=0.9)\n",
    "    f = {}\n",
    "    for x in edges:\n",
    "        p = connectome.get_bundles_of_edge(x)\n",
    "        total = sum(p.values())\n",
    "        for k in p:\n",
    "            frac = p[k] / total\n",
    "            if frac > 0.1:\n",
    "                f[k] = frac\n",
    "    major_edges[sub] = set(f.keys())\n",
    "    \n",
    "    bundles = [re.search(r\"^cluster_(\\d+)$\", str(Path(d[\"bundle_paths\"][x]).stem))[1] for x in f.keys()]\n",
    "    for bundle in bundles:\n",
    "        bundle_counts[cat-1][bundle] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = pd.concat([\n",
    "    pd.DataFrame({\"counts\": bundle_counts[x], \"category\": cats[x+1]}) for x in range(4)\n",
    "])\n",
    "fig = px.bar(\n",
    "    df,\n",
    "    y=\"counts\",\n",
    "    color=\"category\",\n",
    "    labels={\n",
    "        \"index\": \"Bundle ID\"\n",
    "    },\n",
    "    title=\"Most central bundles across subjects\",\n",
    "    width=1178,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_assignments = {}\n",
    "for path in Path(\"resources/tract-assignments\").iterdir():\n",
    "    if path.name in [\"commissural\", \"hemispheric\"]:\n",
    "        continue\n",
    "    with path.open('r') as f:\n",
    "        bundles = [re.search(r\"^cluster_(\\d+)\\.vtp$\", s)[1] for s in f.readlines()]\n",
    "    tract_assignments[path.name] = bundles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "agg = df.set_index(\"category\", append=True).groupby(level=0).sum()[\"counts\"]\n",
    "agg = agg.where(agg > 0).dropna()\n",
    "key_tracts = defaultdict(list)\n",
    "for bundle in agg.where(agg > agg.quantile(0.7)).dropna().index:\n",
    "    for name, tract in tract_assignments.items():\n",
    "        if bundle in tract:\n",
    "            key_tracts[name].append(bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(tract_assignments[\"T_Sup-F\"], it.count()))[\"00408\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "subject = \"008\"\n",
    "\n",
    "with open(layout.get(subject=subject, suffix=\"connectome\", hemi=\"L\")[0].path, 'rb') as f:\n",
    "    connectome = pickle.load(f)\n",
    "matrix = copy.deepcopy(connectome[\"connectome\"].matrix)\n",
    "np.fill_diagonal(matrix, 0)\n",
    "G = nx.from_numpy_matrix(matrix)\n",
    "for edge in G.edges:\n",
    "    G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "\n",
    "df = betweenness(nx.betweenness_centrality(G, weight=\"distance\"), threshold=0)\n",
    "path = layout.get(subject=subject, suffix=\"parcellation\", extension=\".vtk\", hemi=\"L\")[0].path\n",
    "\n",
    "df = pd.concat([\n",
    "    df,\n",
    "    node_sizes(path),\n",
    "    pd.DataFrame({\"degree\": list(dict(G.degree).values())})\n",
    "], axis=1)\n",
    "df = df.sort_values([\"betweenness\"], ascending=True).reset_index(drop=True)\n",
    "\n",
    "fig  = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df[\"node_size\"], mode=\"markers\"),\n",
    "    secondary_y=True\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df[\"betweenness\"], mode=\"markers\"),\n",
    "    secondary_y=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_layout.get(subject=\"001\", suffix=\"smoothwm\", extension=\".surf.gii\", hemi=\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs():\n",
    "    for bidsfile in layout.get(suffix=\"connectome\"):\n",
    "        with open(bidsfile.path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        np.fill_diagonal(data, 0)\n",
    "        G = nx.from_numpy_matrix(data)\n",
    "        yield G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness(b_vals, threshold=.5):\n",
    "    vals = b_vals.values()\n",
    "    b_range = max(vals) - min(vals)\n",
    "    margin = b_range*threshold + min(vals)\n",
    "    above = dict(filter(lambda val: val[1]>margin, b_vals.items()))\n",
    "    return list(above.keys())\n",
    "    return len(above) / len(b_vals)\n",
    "\n",
    "    # b = dict(zip(it.count(), sorted(b_vals)))\n",
    "    # df = pd.DataFrame({\"betweenness\": b})\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        connectome = pickle.load(f)\n",
    "    data = copy.deepcopy(connectome[\"connectome\"].matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "    b_vals = nx.betweenness_centrality(G, weight=\"distance\")\n",
    "    \n",
    "    sizes = node_sizes_relative(layout.get(subject=bidsfile.entities['subject'], suffix=\"parcellation\", hemi=\"L\")[0].path)\n",
    "    degrees = degree_sizes_relative(dict(G.degree(weight=\"weight\")))\n",
    "    for threshold in np.arange(0, 1, 0.1):\n",
    "        b_nodes = betweenness(b_vals, threshold)\n",
    "        smallest = min(sizes[i] for i in b_nodes)\n",
    "        lowest_degree = min(degrees[i] for i in b_nodes)\n",
    "        \n",
    "        # weight_above = sum([G.edges[edge][\"weight\"] for edge in high_edges])\n",
    "        # total_weight = sum(list(zip(*G.edges(data=\"weight\")))[2])\n",
    "        rows.append({\n",
    "            \"sub\": sub,\n",
    "            \"category\": cat,\n",
    "            \"threshold\": threshold,    \n",
    "            \"smallest_node\": smallest,\n",
    "            \"lowest_degree\": lowest_degree\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"category\"] = df[\"category\"].astype(\"uint32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "grouped = df.groupby([\"category\", \"threshold\"]).mean()\n",
    "dev = df.groupby([\"category\", \"threshold\"]).std()\n",
    "fig = px.line(\n",
    "    grouped,\n",
    "    x=grouped.index.get_level_values(\"threshold\"),\n",
    "   \ty=\"smallest_node\",\n",
    "   \tcolor=grouped.index.get_level_values(\"category\"),\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"x\": \"Betweenness (percentile)\",\n",
    "        \"smallest_node\": \"Smallest Node (percentile)\",\n",
    "        \"degree\": \"Degree\",\n",
    "        \"lowest_degree\": \"Lowest Degree (percentile)\",\n",
    "    },\n",
    "    title=\"Minimum size of nodes of given betweenness\",\n",
    "    error_y=dev[\"lowest_degree\"],\n",
    "    markers=True\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        connectome = pickle.load(f)\n",
    "    data = copy.deepcopy(connectome.matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "    b_vals = nx.betweenness_centrality(G, weight=\"distance\")\n",
    "    \n",
    "    sizes = node_sizes(layout.get(subject=bidsfile.entities['subject'], suffix=\"parcellation\", hemi=\"L\")[0].path)\n",
    "    ddf = pd.concat([\n",
    "        sizes,\n",
    "        pd.DataFrame({\n",
    "            \"degree\": [d for _, d in G.degree(weight=\"weight\")],\n",
    "            \"betweenness\": list(b_vals.values()),\n",
    "        })\n",
    "    ], axis=1)\n",
    "    ddf[\"subject\"] = sub\n",
    "    ddf[\"category\"] = cat\n",
    "    rows.append(ddf)\n",
    "\n",
    "df = pd.concat(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    df[df[\"category\"] == 1],\n",
    "    x=\"degree\",\n",
    "   \ty=\"betweenness\",\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"x\": \"Betweenness (proportion)\",\n",
    "        \"smallest_node\": \"Smallest Node (proportion)\",\n",
    "        \"node_size\": \"Node size\",\n",
    "        \"degree\": \"Degree\",\n",
    "        \"betweenness\": \"Betweenness\",\n",
    "    },\n",
    "    title=\"Correlation between degree and betweenness\",\n",
    "    trendline=\"ols\",\n",
    "    color_discrete_sequence=[\"darkslategray\"],\n",
    "    opacity=0.6,\n",
    "    trendline_color_override=\"blue\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False,\n",
    "    width=584,\n",
    "    height=400,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.get_trendline_results(fig).px_fit_results.iloc[0].rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spaced_elements(arr, count):\n",
    "    result = []\n",
    "    for i in np.round(np.linspace(0, len(arr) - 1, count)).astype(int):\n",
    "        result.append(arr[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "num_points = 20\n",
    "rows = []\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        connectome = pickle.load(f)\n",
    "    data = copy.deepcopy(connectome[\"connectome\"].matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "\n",
    "    b_vals = sorted(nx.betweenness_centrality(G, weight=\"distance\").values())\n",
    "    sizes = sorted(node_sizes(layout.get(subject=bidsfile.entities['subject'], suffix=\"parcellation\", hemi=\"L\")[0].path).values())\n",
    "    degrees = sorted(dict(G.degree(weight=\"weight\")).values())\n",
    "    rows.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"betweenness\": get_spaced_elements(b_vals, num_points),\n",
    "                \"node_size\": get_spaced_elements(sizes, num_points),\n",
    "                \"degree\": get_spaced_elements(degrees, num_points),\n",
    "            },\n",
    "            index=range(num_points),\n",
    "        ).assign(subject=sub, category=cat)\n",
    "    )\n",
    "    \n",
    "df = pd.concat(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"degree\"\n",
    "gb = (\n",
    "    df.assign(index=df.index.to_series() / (num_points - 1))\n",
    "    .groupby([\"category\", \"index\"])\n",
    ")\n",
    "ddf = pd.concat([gb.mean(), gb.std().rename(lambda n: str(n)+\"_std\", axis=1)], axis=1)\n",
    "ddf = ddf.sort_values(column).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "fig = px.line(\n",
    "    ddf,\n",
    "    x=\"index\",\n",
    "    y=column,\n",
    "    color=\"category\",\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"x\": \"Nodes sorted by increasing betweeness\",\n",
    "        \"node_size\": \"Node Size (# triangles)\",\n",
    "        \"betweenness\": \"Betweenness\",\n",
    "        \"degree\": \"Degree\"\n",
    "    },\n",
    "    title=\"Degree distribution\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")\n",
    "for i in ddf[\"category\"].unique():\n",
    "    dddf = ddf[ddf[\"category\"] == i]\n",
    "\n",
    "    fig.add_traces([\n",
    "        go.Scatter(\n",
    "            x=dddf[\"index\"],\n",
    "            y=dddf[column+\"_std\"]+dddf[column],\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=0),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=dddf[\"index\"],\n",
    "            y=dddf[column]-dddf[column+\"_std\"],\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=0),\n",
    "            fill='tonexty',\n",
    "            fillcolor=f'rgba{(*hex_to_rgb(px.colors.qualitative.Plotly[i-1]), 0.2)}'\n",
    "        )\n",
    "    ])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "grouped = df.groupby([\"category\", \"point\"]).mean()\n",
    "dev = df.groupby([\"category\", \"point\"]).std()\n",
    "dev_up = grouped + dev\n",
    "dev_down = grouped - dev\n",
    "x = grouped.index.get_level_values(\"point\")\n",
    "color = grouped.index.get_level_values(\"category\")\n",
    "fig = px.line(\n",
    "    grouped,\n",
    "    x=grouped.index.get_level_values(\"point\"),\n",
    "    y=column,\n",
    "    color=grouped.index.get_level_values(\"category\"),\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"x\": \"Nodes sorted by increasing betweeness\",\n",
    "        \"node_size\": \"Node Size (# triangles)\",\n",
    "        \"degree\": \"Degree\"\n",
    "    },\n",
    "    title=\"Node size distribution\",\n",
    "    error_y=dev[column],\n",
    "    markers=True\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        connectome = pickle.load(f)\n",
    "    data = copy.deepcopy(connectome.matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    \n",
    "    size = mesh_size(layout.get(subject=bidsfile.entities['subject'], suffix=\"parcellation\", hemi=\"L\")[0].path)\n",
    "    total = mesh_size(raw_layout.get(subject=bidsfile.entities['subject'], suffix='smoothwm', hemi=\"L\")[0].path)\n",
    "\n",
    "    rows.append({\n",
    "        \"sub\": sub,\n",
    "        \"category\": cats[cat],\n",
    "        \"used\": size/total,\n",
    "        \"lost_fibers\": connectome.lost_fibers if connectome.lost_fibers > 0 else np.NaN,\n",
    "        \"num_fibers\": np.sum(data),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.violin(\n",
    "    df,\n",
    "    x=\"category\",\n",
    "    color=\"category\",\n",
    "    y=\"num_fibers\",\n",
    "    points=\"outliers\",\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"num_regions\": \"# Regions\",\n",
    "        \"category\": \"Group\",\n",
    "        \"used\": \"proportion of triangles\",\n",
    "        \"num_fibers\": \"Number of fibers\",\n",
    "    },\n",
    "    title=\"Number of fibers in connectome\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
