{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ATLAS = \"bn246\"\n",
    "WEIGHT = \"minFA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import subprocess as sp\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import more_itertools as itx\n",
    "import shutil\n",
    "from typing import Any, List\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    4,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    3,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    3,\n",
    "    3,\n",
    "    3,\n",
    "    3,\n",
    "    4,\n",
    "    1,\n",
    "    3,\n",
    "    4,\n",
    "    2,\n",
    "    0,\n",
    "    4,\n",
    "    1,\n",
    "    1,\n",
    "    3,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = {\n",
    "    1: \"HC\",\n",
    "    2: \"FEP\",\n",
    "    3: \"Treatment 3+ yr\",\n",
    "    4: \"High risk\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids import BIDSLayout\n",
    "\n",
    "# layout = BIDSLayout(\"results/prepdwi_recon\", validate=False)\n",
    "layout = BIDSLayout(\"../..\", derivatives=True, database_path=\"../../.pybids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_logile(matrix, bin: int, num_bins: int = 10):\n",
    "    if bin >= num_bins:\n",
    "        raise ValueError(\"bin must be less then num_bins\")\n",
    "    masked = np.ma.masked_equal(matrix, 0)\n",
    "    log = np.ma.log10(masked)\n",
    "    threshold = ((log.max() - log.min()) * bin / num_bins) + log.min()\n",
    "    cp = copy.deepcopy(matrix)\n",
    "    cp[log <= threshold] = 0\n",
    "    return cp\n",
    "\n",
    "def hex_to_rgb(hex_color: str) -> tuple:\n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    if len(hex_color) == 3:\n",
    "        hex_color = hex_color * 2\n",
    "    return int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)\n",
    "\n",
    "def get_lut(path):\n",
    "    with open(path) as f:\n",
    "        lines = [line.strip().split() for line in f.readlines()]\n",
    "    return {int(key): val for key, val in zip(*list(zip(*lines))[0:2])}\n",
    "\n",
    "def lut_label(data, path):\n",
    "    lut = get_lut(path)\n",
    "    return pd.DataFrame(data).rename(index=lut, columns=lut)\n",
    "\n",
    "\n",
    "def titleize(label):\n",
    "    return label.replace(\"_\", \" \").capitalize()\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "def distribution_plot(df, x, y: str):\n",
    "\n",
    "    std_col = y+\"_std\"\n",
    "    grouper = df.groupby([\"category\", x])\n",
    "    ddf = pd.concat([\n",
    "        grouper.mean(),\n",
    "        grouper.std().rename({y: std_col}, axis=\"columns\"),\n",
    "    ], axis=1).reset_index().set_index(\"category\")\n",
    "    fig = px.line(\n",
    "        ddf,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        color=ddf.index,\n",
    "        width=800,\n",
    "        height=600,\n",
    "        labels={\n",
    "            \"x\": \"Nodes sorted by increasing degree\",\n",
    "            \"node_size\": \"Node Size (# triangles)\",\n",
    "            \"betweenness\": \"Betweenness\",\n",
    "            \"degree\": \"Degree\"\n",
    "        },\n",
    "        title=f\"{titleize(y)} distribution\",\n",
    "    )\n",
    "    buttons = []\n",
    "    num_traces = len(ddf.index.unique())\n",
    "    for i, cat in enumerate(ddf.index.unique()):\n",
    "        fig.add_traces([\n",
    "            go.Scatter(\n",
    "                x=ddf.loc[cat, x],\n",
    "                y=ddf.loc[cat, std_col]+ddf.loc[cat,y],\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=0),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=ddf.loc[cat, x],\n",
    "                y=ddf.loc[cat,y]-ddf.loc[cat, std_col],\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=0),\n",
    "                fill='tonexty',\n",
    "                fillcolor=f'rgba{(*hex_to_rgb(px.colors.qualitative.Plotly[i]), 0.2)}'\n",
    "            )\n",
    "        ])\n",
    "        buttons.append({\n",
    "            \"method\": 'restyle',\n",
    "            \"visible\": True,\n",
    "            \"label\": cat,\n",
    "            \"args\": [{\n",
    "                \"visible\": False\n",
    "            }, [i, num_traces + i*2, num_traces + i*2 + 1]],\n",
    "            \"args2\": [{\n",
    "                \"visible\": True,\n",
    "            }, [i, num_traces + i*2, num_traces + i*2 + 1]]\n",
    "        })\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=50, r=50, t=50, b=50),\n",
    "        showlegend=False,\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"buttons\",\n",
    "                direction=\"right\",\n",
    "                x=1,\n",
    "                y=-0.2,\n",
    "                showactive=True,\n",
    "                buttons=buttons,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def figures_to_html(figs, filename=\"dashboard.html\"):\n",
    "    Path(filename).parent.mkdir(exist_ok=True)\n",
    "    with open(filename, 'w') as dashboard:\n",
    "        dashboard.write(\"<html><head></head><body>\" + \"\\n\")\n",
    "        for fig in figs:\n",
    "            inner_html = fig.to_html().split('<body>')[1].split('</body>')[0]\n",
    "            dashboard.write(inner_html)\n",
    "        dashboard.write(\"</body></html>\" + \"\\n\")\n",
    "\n",
    "def plotly_tabulate(figs):\n",
    "    figs = list(figs)\n",
    "    titles = [fig.layout[\"title\"][\"text\"] for fig in figs]\n",
    "    tab = widgets.Tab()\n",
    "    tab.children = [go.FigureWidget(fig) for fig in figs]\n",
    "    for i, title in enumerate(titles):\n",
    "        tab.set_title(i, title)\n",
    "    return tab\n",
    "\n",
    "class NbCache:\n",
    "    def __init__(self, *indices: str, root=\".\"):\n",
    "        self.indicies = indices\n",
    "        self.root = root\n",
    "\n",
    "    def __call__(self, name, reset_cache=False):\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        cache_file = (self.cache_dir / name).with_suffix(\".pyc\")\n",
    "        def do_cache(func, *args, **kwargs):\n",
    "            if cache_file.exists() and not reset_cache:\n",
    "                with cache_file.open('rb') as f:\n",
    "                    return pickle.load(f)\n",
    "            result = func(*args, **kwargs)\n",
    "            with cache_file.open('wb') as f:\n",
    "                pickle.dump(result, f)\n",
    "            return result\n",
    "        def wrapper(func) -> Any:\n",
    "            def inner(*args, **kwargs):\n",
    "                return do_cache(func, *args, **kwargs)\n",
    "            return inner\n",
    "        return wrapper\n",
    "\n",
    "    @property\n",
    "    def cache_dir(self):\n",
    "        return Path(self.root, \".ipynb_cache\", *self.indicies)\n",
    "\n",
    "    def migrate(self, new: \"NbCache\", dry: bool = False):\n",
    "        new.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for path in self.cache_dir.iterdir():\n",
    "            if path.is_dir():\n",
    "                continue\n",
    "            dest = new.cache_dir / path.name\n",
    "            if dry:\n",
    "                print(path, \"->\", dest)\n",
    "                continue\n",
    "            shutil.move(str(path), dest)\n",
    "\n",
    "nb_cache = NbCache(ATLAS, WEIGHT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Subject\n",
    "\n",
    "Here, test a single subject and view the connection density as a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.genfromtxt(\n",
    "    layout.get(\n",
    "        subject=\"034\", datatype=\"dwi\", atlas=ATLAS, suffix=\"connectome\", desc=WEIGHT\n",
    "    )[0].path, \n",
    "    delimiter=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_logile(c, 3)\n",
    "np.fill_diagonal(filtered, 0)\n",
    "G = nx.from_numpy_matrix(filtered)\n",
    "import math\n",
    "for edge in G.edges:\n",
    "    G.edges[edge][\"distance\"] = -math.log10(G.edges[edge][\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = get_lut(\"resources/BN_Atlas_freesurfer/BN_Atlas_246_LUT.txt\")\n",
    "df = pd.DataFrame(filtered).rename(index=lut, columns=lut)\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df, cmap=\"rocket\", square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIGjs2xlpdlg"
   },
   "outputs": [],
   "source": [
    "# Weight distribution plot\n",
    "bins = np.arange(np.sqrt(len(np.concatenate(filtered))))\n",
    "bins = (bins - np.min(bins))/np.ptp(bins)\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "# Distribution of raw weights\n",
    "rawdist = sns.histplot(filtered.flatten(), bins=bins, kde=False, ax=axes[0])\n",
    "rawdist.set(xlabel='Correlation Values', ylabel = 'Density Frequency')\n",
    "\n",
    "# Probability density of log10\n",
    "log10dist = sns.histplot(np.log10(filtered).flatten(), kde=False, ax=axes[1])\n",
    "log10dist.set(xlabel='log(weights)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Subjects\n",
    "\n",
    "Loop through all subjects and gather various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_graphs(filter_level = 1, drop = []):\n",
    "    for bidsfile in layout.get(datatype=\"dwi\", suffix=\"connectome\", atlas=ATLAS, desc=WEIGHT):\n",
    "        sub = int(bidsfile.entities['subject'])\n",
    "        if len(categories) <= sub:\n",
    "            print(f\"Dropped {sub} (out of range)\")\n",
    "            continue\n",
    "        cat = categories[sub]\n",
    "        if cat not in cats:\n",
    "            print(f\"Dropped {sub} (no diagnosis assigned)\")\n",
    "            continue\n",
    "        c = np.genfromtxt(bidsfile.path, delimiter=\",\")\n",
    "        np.fill_diagonal(c, 0)\n",
    "        filtered = filter_logile(c, filter_level)\n",
    "        df = lut_label(filtered, \"resources/BN_Atlas_freesurfer/BN_Atlas_246_LUT.txt\")\n",
    "        df.drop(index=\"Unknown\", columns=\"Unknown\", inplace=True)\n",
    "        dropped = drop(sub) if callable(drop) else drop\n",
    "        df.drop(index=dropped, columns=dropped, inplace=True)\n",
    "        G = nx.from_pandas_adjacency(df)\n",
    "        for edge in G.edges:\n",
    "            G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "        yield sub, cat, G, dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_properties(sub, cat, G, drop_regions = []):\n",
    "        try:\n",
    "            return {\n",
    "                \"subject\": sub,\n",
    "                \"category\": cats[cat],\n",
    "                \"degree\":np.mean([*zip(*G.degree)][1]),\n",
    "                \"num_regions\": len(G.nodes),\n",
    "                \"dropped_regions\": list(drop_regions),\n",
    "                \"num_connected_comps\": nx.number_connected_components(G),\n",
    "                \"largest_connected_comp\": len(max(nx.connected_components(G), key=len)),\n",
    "                \"density\": nx.density(G),\n",
    "                \"transitivity\": nx.transitivity(G),\n",
    "                \"efficiency\": nx.global_efficiency(G)\n",
    "            }\n",
    "        except KeyError as err:\n",
    "            print(sub)\n",
    "            raise err\n",
    "\n",
    "def subject_df(drop_regions = []):\n",
    "    rows = []\n",
    "    for sub, cat, G, dropped in subject_graphs(drop=drop_regions):\n",
    "        try:\n",
    "            rows.append(subject_properties(sub, cat, G, dropped))\n",
    "        except KeyError as err:\n",
    "            print(sub)\n",
    "            raise err\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "@nb_cache(\"subject_full_df\")\n",
    "def subject_full_df():\n",
    "    return subject_df()\n",
    "\n",
    "def subject_distributions(col):\n",
    "    df = subject_full_df()\n",
    "    fig = px.violin(\n",
    "        df,\n",
    "        x=\"category\",\n",
    "        color=\"category\",\n",
    "        y=col,\n",
    "        points=\"outliers\",\n",
    "        width=584,\n",
    "        height=400,\n",
    "        labels={\n",
    "            \"num_regions\": \"# Regions\",\n",
    "            \"category\": \"Group\"\n",
    "        },\n",
    "        title=titleize(col),\n",
    "        hover_data=[\"subject\"]\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=50, r=50, t=50, b=50),\n",
    "        showlegend=False\n",
    "    )\n",
    "    return fig\n",
    "cols = [\n",
    "    \"transitivity\",\n",
    "    \"efficiency\",\n",
    "    \"density\",\n",
    "    \"num_connected_comps\",\n",
    "    \"largest_connected_comp\",\n",
    "    \"degree\",\n",
    "]\n",
    "plotly_tabulate([subject_distributions(col) for col in cols])\n",
    "# figures_to_html([\n",
    "#     subject_distributions(col)\n",
    "#     for col in [\n",
    "#         \"transitivity\",\n",
    "#         \"efficiency\",\n",
    "#         \"density\",\n",
    "#         \"num_connected_comps\",\n",
    "#         \"largest_connected_comp\",\n",
    "#         \"degree\",\n",
    "#     ]\n",
    "# ], \"pages/bn246/subject_distributions.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb_cache(\"nodal_properties\")\n",
    "def nodal_properties():\n",
    "    rows = []\n",
    "    for sub, cat, G, _ in subject_graphs(1):\n",
    "        b = nx.betweenness_centrality(G, weight=\"distance\")\n",
    "        for node in G:\n",
    "            rows.append({\n",
    "                \"node\": node,\n",
    "                \"subject\": sub,\n",
    "                \"category\": cats[cat],\n",
    "                \"degree\": G.degree[node],\n",
    "                \"clust_coeff\": nx.clustering(G, nodes=node),\n",
    "                \"path_length\": np.mean(list(nx.shortest_path_length(G, source=node, weight=\"distance\").values())),\n",
    "                \"betweenness\": b[node],\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "def property_rank(df, columns=[], inverse_columns=[]):\n",
    "    names = df.index.names[:-1]\n",
    "    def rank(df, column, inverse=False):\n",
    "        df.sort_index(inplace=True)\n",
    "        sort = df.sort_values(by=[*names, column], ascending=not inverse)\n",
    "        for cat in df.reset_index().set_index(names).index.unique():\n",
    "            nodes = sort.loc[cat].index\n",
    "            for i, node in enumerate(nodes):\n",
    "                df.loc[\n",
    "                    (*itx.always_iterable(cat), node), f\"{column}_rank\"\n",
    "                ] = i/len(nodes)\n",
    "    for column in columns:\n",
    "        print(f\"Ranking {column}\")\n",
    "        rank(df, column)\n",
    "    for column in inverse_columns:\n",
    "        print(f\"Ranking {column}\")\n",
    "        rank(df, column, inverse=True)\n",
    "    return df\n",
    "\n",
    "def hubness(df, threshold = None, ivars=[\"category\"]):\n",
    "    grouped = df.groupby([*ivars, \"node\"]).mean()\n",
    "    cols = [\"betweenness\", \"degree\"]\n",
    "    inv_cols = [\"path_length\", \"clust_coeff\"]\n",
    "    ranked = property_rank(grouped, columns=cols, inverse_columns=inv_cols)\n",
    "    ranked[\"hubness\"] = 0\n",
    "    for col in it.chain(cols, inv_cols):\n",
    "        if threshold is None:\n",
    "            ranked[\"hubness\"] += ranked[f\"{col}_rank\"]\n",
    "        else:\n",
    "            ranked[\"hubness\"] += (ranked[f\"{col}_rank\"] > threshold).astype(int)\n",
    "    return ranked\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= [\n",
    "    \"betweenness\",\n",
    "    \"clust_coeff\",\n",
    "    \"path_length\",\n",
    "    \"degree\",\n",
    "]\n",
    "indexed = property_rank(nodal_properties().set_index([\"category\", \"subject\", \"node\"]), cols)\n",
    "plotly_tabulate(distribution_plot(indexed, x=col+\"_rank\", y=col) for col in cols)\n",
    "# figures_to_html(\n",
    "#     [\n",
    "#         distribution_plot(indexed, x=col+\"_rank\", y=col) \n",
    "#         for col in cols\n",
    "#     ],\n",
    "#     filename=\"pages/bn246/nodal_distributions.html\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hub_disruption_index(group, cols):\n",
    "    df = nodal_properties()\n",
    "    indexed = df.set_index([\"category\"])\n",
    "    hc = indexed.loc[\"HC\"]\n",
    "    avg = hc.groupby(\"node\").mean()[cols]\n",
    "    group_values = indexed.loc[group].reset_index().pivot(columns=\"node\", index=\"subject\", values=cols)\n",
    "    delta = group_values - avg\n",
    "    delta = pd.DataFrame(delta.stack(), columns=[\"delta\"])\n",
    "    delta[\"avg\"] = avg.reindex(delta.index, level=\"node\")\n",
    "    delta[\"Delta Total\"] = delta.reset_index().groupby(\"subject\").sum()[\"delta\"].reindex(delta.index, level=\"subject\")\n",
    "    return delta.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= [\n",
    "    \"betweenness\",\n",
    "    \"clust_coeff\",\n",
    "    \"path_length\",\n",
    "    \"degree\",\n",
    "]\n",
    "plotly_tabulate(\n",
    "    px.scatter(\n",
    "        hub_disruption_index(\"FEP\", col),\n",
    "        x=\"avg\",\n",
    "        y=\"delta\",\n",
    "        color=\"Delta Total\",\n",
    "        trendline=\"ols\",\n",
    "        title=titleize(col),\n",
    "        hover_data=[\"subject\", \"node\"]\n",
    "    )\n",
    "    for col in cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb_cache(\"hubness\")\n",
    "def get_hubs():\n",
    "    return hubness(nodal_properties(), ivars=[\"category\", \"subject\"])\n",
    "hubs = get_hubs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [\"degree\", \"clust_coeff\", \"path_length\", \"betweenness\"]\n",
    "\n",
    "plt.figure(figsize=(30, 50))\n",
    "plt.subplot(1, 3, 1)\n",
    "table1 = (\n",
    "    hubs\n",
    "    .loc[\"HC\"]\n",
    "    .reset_index()\n",
    "    .pivot(index=\"node\", columns=\"subject\", values=\"hubness\")\n",
    ")\n",
    "sns.heatmap(table1, cmap=\"viridis\", square=True, cbar=False)\n",
    "plt.subplot(1, 3, (2,3))\n",
    "table2 = (\n",
    "    hubs\n",
    "    .loc[\"FEP\"]\n",
    "    .reset_index()\n",
    "    .pivot(index=\"node\", columns=\"subject\", values=\"hubness\")\n",
    ")\n",
    "sns.heatmap(table2, cmap=\"viridis\", square=True, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drop_func(i, hub_df):\n",
    "    indexed = (\n",
    "        hub_df\n",
    "        .reset_index()\n",
    "        .set_index([\"subject\", \"node\"])\n",
    "        .sort_values([\"subject\", \"hubness\"], ascending=False)\n",
    "    )\n",
    "    def drop_func(sub):\n",
    "        return indexed.loc[sub].index[:i]\n",
    "    return drop_func\n",
    "    \n",
    "\n",
    "def _get_subject_df(x):\n",
    "    return subject_df(drop_regions=get_drop_func(x, hubs))\n",
    "import multiprocessing as mp\n",
    "@nb_cache(\"attack_analysis\")\n",
    "def attack_analysis():\n",
    "    with mp.Pool(processes=32) as pool:\n",
    "        dfs = pool.map(\n",
    "            _get_subject_df,\n",
    "            range(hubs.reset_index().groupby(\"subject\").count().max()[0])\n",
    "        )\n",
    "    # for i in range(hubs.reset_index().groupby(\"subject\").count().max()[0]):\n",
    "    #     dfs.append(subject_df(drop_regions = get_drop_func(i, hubs)))\n",
    "    return pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = attack_analysis()\n",
    "df[\"num_dropped\"] = df[\"num_regions\"].max() - df[\"num_regions\"]\n",
    "plotly_tabulate(\n",
    "    distribution_plot(df, x=\"num_dropped\", y=col) \n",
    "    for col in [\n",
    "        \"transitivity\",\n",
    "        \"efficiency\",\n",
    "        \"density\",\n",
    "        \"num_connected_comps\",\n",
    "        \"largest_connected_comp\",\n",
    "        \"degree\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [\"degree\", \"clust_coeff\", \"path_length\", \"betweenness\"]\n",
    "df = nodal_properties()\n",
    "\n",
    "table = (\n",
    "    hubness(df)\n",
    "    .reset_index()\n",
    "    .pivot(index=\"node\", columns=\"category\", values=\"hubness\")\n",
    "    .reindex(columns=[\"HC\", \"FEP\", \"Treatment 3+ yr\", \"High risk\"])\n",
    ")\n",
    "plt.figure(figsize=(20,40))\n",
    "sns.heatmap(table, cmap=\"viridis\", square=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
