{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import subprocess as sp\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    2,\n",
    "    4,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    3,\n",
    "    3,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    4,\n",
    "    3,\n",
    "    3,\n",
    "    3,\n",
    "    3,\n",
    "    4,\n",
    "    1,\n",
    "    3,\n",
    "    4,\n",
    "    2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = {\n",
    "    1: \"HC\",\n",
    "    2: \"FEP\",\n",
    "    3: \"Treatment 3+ yr\",\n",
    "    4: \"High risk\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids import BIDSLayout\n",
    "\n",
    "layout = BIDSLayout(\"results/prepdwi_recon\", validate=False)\n",
    "raw_layout = BIDSLayout(\"../..\", validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fury.io as fio\n",
    "import fury.utils as futil\n",
    "import fury.lib as flib\n",
    "import nibabel as nib\n",
    "def node_sizes(path):\n",
    "    pld = fio.load_polydata(path)\n",
    "    cluster_id = flib.numpy_support.vtk_to_numpy(pld.GetCellData().GetArray(\"parcel_idx\"))\n",
    "    counts = defaultdict(lambda: 0)\n",
    "    for i in cluster_id:\n",
    "        counts[i] += 1\n",
    "    return counts\n",
    "\n",
    "def node_sizes_relative(path):\n",
    "    pld = fio.load_polydata(path)\n",
    "    cluster_id = flib.numpy_support.vtk_to_numpy(pld.GetCellData().GetArray(\"parcel_idx\"))\n",
    "    counts = [0] * (max(cluster_id)+1)\n",
    "    for i in cluster_id:\n",
    "        counts[i] += 1\n",
    "    spread = max(counts) - min(counts)\n",
    "    for i in range(len(counts)):\n",
    "        counts[i] = counts[i]/spread\n",
    "    return counts\n",
    "\n",
    "\n",
    "def degree_sizes_relative(degrees):\n",
    "    spread = max(degrees.values()) - min(degrees.values())\n",
    "    for i in range(len(degrees)):\n",
    "        degrees[i] = degrees[i]/spread\n",
    "    return degrees\n",
    "\n",
    "def mesh_size(path):\n",
    "    if Path(path).suffix in [\".vtk\", \".vtp\"]:\n",
    "        pld = fio.load_polydata(path)\n",
    "        return len(futil.get_polydata_triangles(pld))\n",
    "    pld = nib.load(path)\n",
    "    return len(pld.agg_data('triangle'))\n",
    "\n",
    "def node_size_at_points(df: pd.DataFrame, points, column):\n",
    "    df = df.sort_values(column).reset_index(drop=True)\n",
    "    num_rows = len(df[column])\n",
    "    return pd.DataFrame({\n",
    "        column: [df[column][int((num_rows-1) * point)] for point in points],\n",
    "        \"point\": points\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness(b_vals, threshold=.5):\n",
    "    vals = b_vals.values()\n",
    "    b_range = max(vals) - min(vals)\n",
    "    margin = b_range*threshold + min(vals)\n",
    "    above = dict(filter(lambda val: val[1]>=margin, b_vals.items()))\n",
    "    # return above\n",
    "    # b = dict(zip(it.count(), sorted(b_vals)))\n",
    "    df = pd.DataFrame({\"betweenness\": above})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resources/tract-assignments/hemispheric\", 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "all_bundles = [re.search(r\"^cluster_(\\d+)\\.vtp$\", s)[1] for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_counts = [dict(zip(all_bundles, it.repeat(0))) for _ in range(4)]\n",
    "major_edges = {}\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    connectome = d[\"connectome\"]\n",
    "    data = copy.deepcopy(connectome.matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "    edges = betweenness(nx.edge_betweenness_centrality(G, weight=\"distance\"), threshold=0.9)\n",
    "    f = {}\n",
    "    for x in edges:\n",
    "        p = connectome.get_bundles_of_edge(x)\n",
    "        total = sum(p.values())\n",
    "        for k in p:\n",
    "            frac = p[k] / total\n",
    "            if frac > 0.1:\n",
    "                f[k] = frac\n",
    "    major_edges[sub] = set(f.keys())\n",
    "    \n",
    "    bundles = [re.search(r\"^cluster_(\\d+)$\", str(Path(d[\"bundle_paths\"][x]).stem))[1] for x in f.keys()]\n",
    "    for bundle in bundles:\n",
    "        bundle_counts[cat-1][bundle] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = pd.concat([\n",
    "    pd.DataFrame({\"counts\": bundle_counts[x], \"category\": cats[x+1]}) for x in range(4)\n",
    "])\n",
    "fig = px.bar(\n",
    "    df,\n",
    "    y=\"counts\",\n",
    "    color=\"category\",\n",
    "    labels={\n",
    "        \"index\": \"Bundle ID\"\n",
    "    },\n",
    "    title=\"Most central bundles across subjects\",\n",
    "    width=1178,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_assignments = {}\n",
    "for path in Path(\"resources/tract-assignments\").iterdir():\n",
    "    if path.name in [\"commissural\", \"hemispheric\"]:\n",
    "        continue\n",
    "    with path.open('r') as f:\n",
    "        bundles = [re.search(r\"^cluster_(\\d+)\\.vtp$\", s)[1] for s in f.readlines()]\n",
    "    tract_assignments[path.name] = bundles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "agg = df.set_index(\"category\", append=True).groupby(level=0).sum()[\"counts\"]\n",
    "agg = agg.where(agg > 0).dropna()\n",
    "key_tracts = defaultdict(list)\n",
    "for bundle in agg.where(agg > agg.quantile(0.7)).dropna().index:\n",
    "    for name, tract in tract_assignments.items():\n",
    "        if bundle in tract:\n",
    "            key_tracts[name].append(bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(tract_assignments[\"T_Sup-F\"], it.count()))[\"00408\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "subject = \"008\"\n",
    "\n",
    "with open(layout.get(subject=subject, suffix=\"connectome\", hemi=\"L\")[0].path, 'rb') as f:\n",
    "    connectome = pickle.load(f)\n",
    "matrix = copy.deepcopy(connectome[\"connectome\"].matrix)\n",
    "np.fill_diagonal(matrix, 0)\n",
    "G = nx.from_numpy_matrix(matrix)\n",
    "for edge in G.edges:\n",
    "    G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "\n",
    "df = betweenness(nx.betweenness_centrality(G, weight=\"distance\"), threshold=0)\n",
    "path = layout.get(subject=subject, suffix=\"parcellation\", extension=\".vtk\", hemi=\"L\")[0].path\n",
    "\n",
    "df = pd.concat([\n",
    "    df,\n",
    "    node_sizes(path),\n",
    "    pd.DataFrame({\"degree\": list(dict(G.degree).values())})\n",
    "], axis=1)\n",
    "df = df.sort_values([\"betweenness\"], ascending=True).reset_index(drop=True)\n",
    "\n",
    "fig  = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df[\"node_size\"], mode=\"markers\"),\n",
    "    secondary_y=True\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df[\"betweenness\"], mode=\"markers\"),\n",
    "    secondary_y=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_layout.get(subject=\"001\", suffix=\"smoothwm\", extension=\".surf.gii\", hemi=\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs():\n",
    "    for bidsfile in layout.get(suffix=\"connectome\"):\n",
    "        with open(bidsfile.path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        np.fill_diagonal(data, 0)\n",
    "        G = nx.from_numpy_matrix(data)\n",
    "        yield G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness(b_vals, threshold=.5):\n",
    "    vals = b_vals.values()\n",
    "    b_range = max(vals) - min(vals)\n",
    "    margin = b_range*threshold + min(vals)\n",
    "    above = dict(filter(lambda val: val[1]>margin, b_vals.items()))\n",
    "    return list(above.keys())\n",
    "    return len(above) / len(b_vals)\n",
    "\n",
    "    # b = dict(zip(it.count(), sorted(b_vals)))\n",
    "    # df = pd.DataFrame({\"betweenness\": b})\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for bidsfile in layout.get(suffix=\"connectome\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        connectome = pickle.load(f)\n",
    "    data = copy.deepcopy(connectome.matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    rows.append({\n",
    "        \"subject\": sub,\n",
    "        \"category\": cats[cat],\n",
    "        \"degree\":np.mean([*zip(*G.degree)][1]),\n",
    "        \"num_regions\": len(G.nodes),\n",
    "        \"transitivity\": nx.transitivity(G),\n",
    "        # \"efficiency\" nx.global_efficiency(G)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.violin(\n",
    "    df,\n",
    "    x=\"category\",\n",
    "    color=\"category\",\n",
    "    y=\"num_regions\",\n",
    "    points=\"outliers\",\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"num_regions\": \"# Regions\",\n",
    "        \"category\": \"Group\"\n",
    "    },\n",
    "    title=\"Number of nodes\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        connectome = pickle.load(f)\n",
    "    data = copy.deepcopy(connectome[\"connectome\"].matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "    b_vals = nx.betweenness_centrality(G, weight=\"distance\")\n",
    "    \n",
    "    sizes = node_sizes_relative(layout.get(subject=bidsfile.entities['subject'], suffix=\"parcellation\", hemi=\"L\")[0].path)\n",
    "    degrees = degree_sizes_relative(dict(G.degree(weight=\"weight\")))\n",
    "    for threshold in np.arange(0, 1, 0.1):\n",
    "        b_nodes = betweenness(b_vals, threshold)\n",
    "        smallest = min(sizes[i] for i in b_nodes)\n",
    "        lowest_degree = min(degrees[i] for i in b_nodes)\n",
    "        \n",
    "        # weight_above = sum([G.edges[edge][\"weight\"] for edge in high_edges])\n",
    "        # total_weight = sum(list(zip(*G.edges(data=\"weight\")))[2])\n",
    "        rows.append({\n",
    "            \"sub\": sub,\n",
    "            \"category\": cat,\n",
    "            \"threshold\": threshold,    \n",
    "            \"smallest_node\": smallest,\n",
    "            \"lowest_degree\": lowest_degree\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"category\"] = df[\"category\"].astype(\"uint32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "grouped = df.groupby([\"category\", \"threshold\"]).mean()\n",
    "dev = df.groupby([\"category\", \"threshold\"]).std()\n",
    "fig = px.line(\n",
    "    grouped,\n",
    "    x=grouped.index.get_level_values(\"threshold\"),\n",
    "   \ty=\"smallest_node\",\n",
    "   \tcolor=grouped.index.get_level_values(\"category\"),\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"x\": \"Betweenness (percentile)\",\n",
    "        \"smallest_node\": \"Smallest Node (percentile)\",\n",
    "        \"degree\": \"Degree\",\n",
    "        \"lowest_degree\": \"Lowest Degree (percentile)\",\n",
    "    },\n",
    "    title=\"Minimum size of nodes of given betweenness\",\n",
    "    error_y=dev[\"lowest_degree\"],\n",
    "    markers=True\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        connectome = pickle.load(f)\n",
    "    data = copy.deepcopy(connectome.matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "    b_vals = nx.betweenness_centrality(G, weight=\"distance\")\n",
    "    \n",
    "    sizes = node_sizes(layout.get(subject=bidsfile.entities['subject'], suffix=\"parcellation\", hemi=\"L\")[0].path)\n",
    "    ddf = pd.concat([\n",
    "        sizes,\n",
    "        pd.DataFrame({\n",
    "            \"degree\": [d for _, d in G.degree(weight=\"weight\")],\n",
    "            \"betweenness\": list(b_vals.values()),\n",
    "        })\n",
    "    ], axis=1)\n",
    "    ddf[\"subject\"] = sub\n",
    "    ddf[\"category\"] = cat\n",
    "    rows.append(ddf)\n",
    "\n",
    "df = pd.concat(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    df[df[\"category\"] == 1],\n",
    "    x=\"degree\",\n",
    "   \ty=\"betweenness\",\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"x\": \"Betweenness (proportion)\",\n",
    "        \"smallest_node\": \"Smallest Node (proportion)\",\n",
    "        \"node_size\": \"Node size\",\n",
    "        \"degree\": \"Degree\",\n",
    "        \"betweenness\": \"Betweenness\",\n",
    "    },\n",
    "    title=\"Correlation between degree and betweenness\",\n",
    "    trendline=\"ols\",\n",
    "    color_discrete_sequence=[\"darkslategray\"],\n",
    "    opacity=0.6,\n",
    "    trendline_color_override=\"blue\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False,\n",
    "    width=584,\n",
    "    height=400,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.get_trendline_results(fig).px_fit_results.iloc[0].rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spaced_elements(arr, count):\n",
    "    result = []\n",
    "    for i in np.round(np.linspace(0, len(arr) - 1, count)).astype(int):\n",
    "        result.append(arr[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "num_points = 20\n",
    "rows = []\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        connectome = pickle.load(f)\n",
    "    data = copy.deepcopy(connectome[\"connectome\"].matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"distance\"] = 1/G.edges[edge][\"weight\"]\n",
    "\n",
    "    b_vals = sorted(nx.betweenness_centrality(G, weight=\"distance\").values())\n",
    "    sizes = sorted(node_sizes(layout.get(subject=bidsfile.entities['subject'], suffix=\"parcellation\", hemi=\"L\")[0].path).values())\n",
    "    degrees = sorted(dict(G.degree(weight=\"weight\")).values())\n",
    "    rows.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"betweenness\": get_spaced_elements(b_vals, num_points),\n",
    "                \"node_size\": get_spaced_elements(sizes, num_points),\n",
    "                \"degree\": get_spaced_elements(degrees, num_points),\n",
    "            },\n",
    "            index=range(num_points),\n",
    "        ).assign(subject=sub, category=cat)\n",
    "    )\n",
    "    \n",
    "df = pd.concat(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_rgb(hex_color: str) -> tuple:\n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    if len(hex_color) == 3:\n",
    "        hex_color = hex_color * 2\n",
    "    return int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"degree\"\n",
    "gb = (\n",
    "    df.assign(index=df.index.to_series() / (num_points - 1))\n",
    "    .groupby([\"category\", \"index\"])\n",
    ")\n",
    "ddf = pd.concat([gb.mean(), gb.std().rename(lambda n: str(n)+\"_std\", axis=1)], axis=1)\n",
    "ddf = ddf.sort_values(column).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "fig = px.line(\n",
    "    ddf,\n",
    "    x=\"index\",\n",
    "    y=column,\n",
    "    color=\"category\",\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"x\": \"Nodes sorted by increasing betweeness\",\n",
    "        \"node_size\": \"Node Size (# triangles)\",\n",
    "        \"betweenness\": \"Betweenness\",\n",
    "        \"degree\": \"Degree\"\n",
    "    },\n",
    "    title=\"Degree distribution\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")\n",
    "for i in ddf[\"category\"].unique():\n",
    "    dddf = ddf[ddf[\"category\"] == i]\n",
    "\n",
    "    fig.add_traces([\n",
    "        go.Scatter(\n",
    "            x=dddf[\"index\"],\n",
    "            y=dddf[column+\"_std\"]+dddf[column],\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=0),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=dddf[\"index\"],\n",
    "            y=dddf[column]-dddf[column+\"_std\"],\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=0),\n",
    "            fill='tonexty',\n",
    "            fillcolor=f'rgba{(*hex_to_rgb(px.colors.qualitative.Plotly[i-1]), 0.2)}'\n",
    "        )\n",
    "    ])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "grouped = df.groupby([\"category\", \"point\"]).mean()\n",
    "dev = df.groupby([\"category\", \"point\"]).std()\n",
    "dev_up = grouped + dev\n",
    "dev_down = grouped - dev\n",
    "x = grouped.index.get_level_values(\"point\")\n",
    "color = grouped.index.get_level_values(\"category\")\n",
    "fig = px.line(\n",
    "    grouped,\n",
    "    x=grouped.index.get_level_values(\"point\"),\n",
    "    y=column,\n",
    "    color=grouped.index.get_level_values(\"category\"),\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"x\": \"Nodes sorted by increasing betweeness\",\n",
    "        \"node_size\": \"Node Size (# triangles)\",\n",
    "        \"degree\": \"Degree\"\n",
    "    },\n",
    "    title=\"Node size distribution\",\n",
    "    error_y=dev[column],\n",
    "    markers=True\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for bidsfile in layout.get(suffix=\"connectome\", hemi=\"L\"):\n",
    "    with open(bidsfile.path, 'rb') as f:\n",
    "        connectome = pickle.load(f)\n",
    "    data = copy.deepcopy(connectome.matrix)\n",
    "    np.fill_diagonal(data, 0)\n",
    "    G = nx.from_numpy_matrix(data)\n",
    "    sub = int(bidsfile.entities['subject'])\n",
    "    cat = categories[sub]\n",
    "    \n",
    "    size = mesh_size(layout.get(subject=bidsfile.entities['subject'], suffix=\"parcellation\", hemi=\"L\")[0].path)\n",
    "    total = mesh_size(raw_layout.get(subject=bidsfile.entities['subject'], suffix='smoothwm', hemi=\"L\")[0].path)\n",
    "\n",
    "    rows.append({\n",
    "        \"sub\": sub,\n",
    "        \"category\": cats[cat],\n",
    "        \"used\": size/total,\n",
    "        \"lost_fibers\": connectome.lost_fibers if connectome.lost_fibers > 0 else np.NaN,\n",
    "        \"num_fibers\": np.sum(data),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.violin(\n",
    "    df,\n",
    "    x=\"category\",\n",
    "    color=\"category\",\n",
    "    y=\"num_fibers\",\n",
    "    points=\"outliers\",\n",
    "    width=584,\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"num_regions\": \"# Regions\",\n",
    "        \"category\": \"Group\",\n",
    "        \"used\": \"proportion of triangles\",\n",
    "        \"num_fibers\": \"Number of fibers\",\n",
    "    },\n",
    "    title=\"Number of fibers in connectome\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
